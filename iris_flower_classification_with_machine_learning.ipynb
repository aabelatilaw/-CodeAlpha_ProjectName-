{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXLIDntl0bbkVn7Hyxej38",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aabelatilaw/-CodeAlpha_ProjectName-/blob/main/iris_flower_classification_with_machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Iris Flower Classification with Machine Learning**"
      ],
      "metadata": {
        "id": "1f4rpW23Vyp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Import Required Libraries"
      ],
      "metadata": {
        "id": "xAg2Ti7GWGuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.datasets import load_iris\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "3PvPx_XJV77O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Load and Explore the Data"
      ],
      "metadata": {
        "id": "pCLC42E9WUar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "df = pd.read_csv('Iris.csv')\n",
        "\n",
        "# Explore the data\n",
        "print(df.head())\n",
        "print(\"\\nData Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(df.describe())\n",
        "print(\"\\nSpecies Count:\")\n",
        "print(df['Species'].value_counts())"
      ],
      "metadata": {
        "id": "uF8ia6wbV73u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Data Preprocessing"
      ],
      "metadata": {
        "id": "0DRRfIM7Wt3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the Id column as it's not needed\n",
        "df = df.drop('Id', axis=1)\n",
        "\n",
        "# Encode the species labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Species'] = label_encoder.fit_transform(df['Species'])\n",
        "\n",
        "# Visualize the data\n",
        "sns.pairplot(df, hue='Species')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XcW3LjUQV70V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Prepare Training and Test Data"
      ],
      "metadata": {
        "id": "JkjQ3pxRW39A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into features and target\n",
        "X = df.drop('Species', axis=1)\n",
        "y = df['Species']\n",
        "\n",
        "# Split into training and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Test set size: {X_test.shape[0]}\")"
      ],
      "metadata": {
        "id": "WZE4UuB7V7w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Train the Model"
      ],
      "metadata": {
        "id": "d31CjaOhXEv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "fTfvHGotV7tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Evaluate the Model"
      ],
      "metadata": {
        "id": "i3_8gc_dXJsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=label_encoder.classes_,\n",
        "            yticklabels=label_encoder.classes_)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nNhMw2q5V7qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Feature Importance Analysis"
      ],
      "metadata": {
        "id": "w4s9FKkpXY3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature importances\n",
        "importances = model.feature_importances_\n",
        "features = X.columns\n",
        "\n",
        "# Create a DataFrame for visualization\n",
        "feature_importance = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
        "feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importance)\n",
        "plt.title('Feature Importance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "13tYCeCIV7n5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Make Predictions on New Data"
      ],
      "metadata": {
        "id": "mqbnSgyVXf4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example new data (sepal length, sepal width, petal length, petal width)\n",
        "new_data = [[5.1, 3.5, 1.4, 0.2],  # Likely setosa\n",
        "            [6.0, 2.7, 5.1, 1.6],  # Likely versicolor\n",
        "            [6.3, 3.3, 6.0, 2.5]]  # Likely virginica\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(new_data)\n",
        "\n",
        "# Convert numeric predictions back to species names\n",
        "predicted_species = label_encoder.inverse_transform(predictions)\n",
        "\n",
        "print(\"\\nPredictions for new data:\")\n",
        "for i, pred in enumerate(predicted_species):\n",
        "    print(f\"Sample {i+1}: Predicted Species = {pred}\")"
      ],
      "metadata": {
        "id": "prCYcaeSV7lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XiJrnGdCV7Wo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}